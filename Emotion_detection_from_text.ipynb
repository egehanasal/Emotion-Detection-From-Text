{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_detection_from_text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CubYcwcQTSoP"
      },
      "source": [
        "#EmDet\n",
        "\n",
        "Purpose of this project is to build an NLP model to predict the emotion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhUAH37gecUX"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaAbtJzweFqx",
        "outputId": "dc42f508-428b-4193-83d6-f080b05eb87a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/egehanasal/Emotion-Detection-From-Text/main/data/Cleaned%20Data/emotion_data_cleaned.csv"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-23 00:58:25--  https://raw.githubusercontent.com/egehanasal/Emotion-Detection-From-Text/main/data/Cleaned%20Data/emotion_data_cleaned.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4538038 (4.3M) [text/plain]\n",
            "Saving to: ‘emotion_data_cleaned.csv’\n",
            "\n",
            "emotion_data_cleane 100%[===================>]   4.33M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-10-23 00:58:25 (58.2 MB/s) - ‘emotion_data_cleaned.csv’ saved [4538038/4538038]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-G6VOlOeLvO",
        "outputId": "8eaa79cb-d360-48c7-87b8-152c987c8b0a"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"emotion_data_cleaned.csv\")\n",
        "df.info()"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60000 entries, 0 to 59999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    59885 non-null  object\n",
            " 1   target  60000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 937.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpMyw41xfMh2"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6QBklG8fB2j",
        "outputId": "b1546bb5-9ffa-4a8a-fb5c-c5c87b39505e"
      },
      "source": [
        "import numpy as np\n",
        "np.where(pd.isnull(df))"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  659,   664,  3181,  4865,  4933,  5230,  5473,  6451,  6838,\n",
              "         6914,  7143,  7475,  8081,  8216,  8707,  8837,  9169,  9229,\n",
              "         9920, 10882, 11111, 11145, 11289, 12098, 12275, 12867, 13810,\n",
              "        13986, 14100, 15232, 15432, 15941, 16054, 16698, 16808, 18020,\n",
              "        18153, 18577, 20502, 20665, 20973, 22569, 22776, 23415, 25049,\n",
              "        25410, 25497, 25527, 26255, 26782, 27122, 27680, 27877, 28789,\n",
              "        28824, 28972, 29208, 29372, 29783, 30257, 30380, 31109, 31852,\n",
              "        32122, 32147, 32153, 33123, 33729, 33816, 33849, 34886, 34952,\n",
              "        38438, 38650, 39206, 39518, 39995, 40659, 40664, 43181, 44865,\n",
              "        44933, 45230, 45473, 46451, 46838, 46914, 47143, 47475, 48081,\n",
              "        48216, 48707, 48837, 49169, 49229, 49920, 50882, 51111, 51145,\n",
              "        51289, 52098, 52275, 52867, 53810, 53986, 54100, 55232, 55432,\n",
              "        55941, 56054, 56698, 56808, 58020, 58153, 58577]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZowwyDqtfKBh",
        "outputId": "ad33fe39-47c3-4127-e1d9-ee5dfa490ff9"
      },
      "source": [
        "np.where(df.applymap(lambda x: x == ''))"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-XIVH06ehTB"
      },
      "source": [
        "Drop the null lines and check the data again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAzLv2qEfZ9K"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMg9YT5vfaQB",
        "outputId": "81844599-30ae-476a-d206-56631062e841"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 59885 entries, 0 to 59999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    59885 non-null  object\n",
            " 1   target  59885 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "NPg9pVtgfaNN",
        "outputId": "7e104622-8b52-47fa-f898-09552b3b742f"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i know i was listenin to bad habit earlier and...</td>\n",
              "      <td>empty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Layin n bed with a headache ughhhh...waitin on...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>enthusiasm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We want to trade with someone who has Houston ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Re-pinging why didn't you go to prom? BC my bf...</td>\n",
              "      <td>worry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
              "      <td>worry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Charlene my love. I miss you</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>I'm sorry at least it's Friday?</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text      target\n",
              "0  i know i was listenin to bad habit earlier and...       empty\n",
              "1  Layin n bed with a headache ughhhh...waitin on...     sadness\n",
              "2                Funeral ceremony...gloomy friday...     sadness\n",
              "3               wants to hang out with friends SOON!  enthusiasm\n",
              "4  We want to trade with someone who has Houston ...     neutral\n",
              "5  Re-pinging why didn't you go to prom? BC my bf...       worry\n",
              "6  I should be sleep, but im not! thinking about ...     sadness\n",
              "7               Hmmm. http://www.djhero.com/ is down       worry\n",
              "8                       Charlene my love. I miss you     sadness\n",
              "9                    I'm sorry at least it's Friday?     sadness"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGyFwxPWfaKF",
        "outputId": "c16d1dfa-cf22-404f-cec3-9dcec307dacd"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "df.target.value_counts()"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sadness       10946\n",
              "neutral        8582\n",
              "worry          8454\n",
              "joy            6747\n",
              "love           5481\n",
              "happiness      5208\n",
              "surprise       2904\n",
              "anger          2814\n",
              "fear           2369\n",
              "fun            1776\n",
              "relief         1526\n",
              "hate           1323\n",
              "empty           816\n",
              "enthusiasm      759\n",
              "boredom         179\n",
              "jo                1\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82JVWireptTg"
      },
      "source": [
        "Let's delete the rows with targets \"jo, boredom, enthusiasm, empty\" since they have less examples compared to others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-BQsHwrtDuO"
      },
      "source": [
        "df.drop(df[df[\"target\"] == \"jo\"].index, inplace=True)\n",
        "df.drop(df[df[\"target\"] == \"boredom\"].index, inplace=True)\n",
        "df.drop(df[df[\"target\"] == \"enthusiasm\"].index, inplace=True)\n",
        "df.drop(df[df[\"target\"] == \"empty\"].index, inplace=True)"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSg2GQBruJj6",
        "outputId": "4d956afa-5a15-49f1-a594-0887fbe2ae8d"
      },
      "source": [
        "df[\"target\"].value_counts()"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sadness      10946\n",
              "neutral       8582\n",
              "worry         8454\n",
              "joy           6747\n",
              "love          5481\n",
              "happiness     5208\n",
              "surprise      2904\n",
              "anger         2814\n",
              "fear          2369\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flQRsngz-Can"
      },
      "source": [
        "Before splitting our data, let's shuffle it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "f9Y936RI-Gkm",
        "outputId": "e0fe1da1-1220-4e08-e9c7-0f1f538cc415"
      },
      "source": [
        "# Shuffle the dataframe\n",
        "df_shuffled = df.sample(frac=1)\n",
        "df_shuffled.head(10)"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11891</th>\n",
              "      <td>friend got mugged this morning</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55187</th>\n",
              "      <td>your not talking about your obsession with me ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34599</th>\n",
              "      <td>just missing you&amp;amp;hoping to talk to you soo...</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37506</th>\n",
              "      <td>Okay I'm about to &amp;quot;crawl&amp;quot; into bed a...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12173</th>\n",
              "      <td>I don't know what im doing :S</td>\n",
              "      <td>worry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51520</th>\n",
              "      <td>Practically my whole body burns... I can't ben...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10782</th>\n",
              "      <td>http://twitpic.com/676tn - Home Sweet Home... ...</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56081</th>\n",
              "      <td>yeah text me!!! i wnat to go!!!!! but my car i...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50157</th>\n",
              "      <td>so no rice or crusty bread with the chili .......</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26121</th>\n",
              "      <td>ill and bored on bank holiday.. Nothings open....</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text     target\n",
              "11891                     friend got mugged this morning    sadness\n",
              "55187  your not talking about your obsession with me ...        joy\n",
              "34599  just missing you&amp;hoping to talk to you soo...  happiness\n",
              "37506  Okay I'm about to &quot;crawl&quot; into bed a...    neutral\n",
              "12173                      I don't know what im doing :S      worry\n",
              "51520  Practically my whole body burns... I can't ben...        joy\n",
              "10782  http://twitpic.com/676tn - Home Sweet Home... ...  happiness\n",
              "56081  yeah text me!!! i wnat to go!!!!! but my car i...       love\n",
              "50157  so no rice or crusty bread with the chili .......    sadness\n",
              "26121  ill and bored on bank holiday.. Nothings open....    sadness"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSuRso1a8rSQ"
      },
      "source": [
        "### Split the data to train, val and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pioMjj0_8wAr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                          df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                          test_size=0.15)"
      ],
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwadh183Bpk2"
      },
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences,\n",
        "                                                                        train_labels,\n",
        "                                                                        test_size=0.1)"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swe0vsSr-b0U",
        "outputId": "11c49c75-c4fe-44af-cb7f-4fd2aab57bb5"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels), len(test_sentences), len(test_labels)"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44469, 44469, 4941, 4941, 8720, 8720)"
            ]
          },
          "metadata": {},
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y534R70T8wDz",
        "outputId": "26cb9a82-eec6-4b61-a097-a0094b855c12"
      },
      "source": [
        "# View first 10 lines of training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([\"just saw an advert for ATTICS TO EDEN on tv out today and only ï¿½9.99 from HMV...so I'm not sure why I had to pay ï¿½13 at HMV...never mind\",\n",
              "        \"is my son - he gets my vote today coz he has grown into a loving, caring 'soul-full' man - who loves his mum\",\n",
              "        'oh about you lol sorry my minds always on you', 'My eyes hurt',\n",
              "        \"WOMAN, I didn't know you came home you so suck!!! When are you going back!\",\n",
              "        'On the way to Wildomar, CA towing the Lexus',\n",
              "        \"I'll be back home on Monday.\",\n",
              "        'I think we all need a oil change wash and wax every now and again',\n",
              "        'i wanna see her hair hows everyone?',\n",
              "        ':O Looking through my old stuff and found a record from my old band! Well,a band that I was in for about a month. Ever heard of ?'],\n",
              "       dtype=object),\n",
              " array(['relief', 'neutral', 'surprise', 'neutral', 'joy', 'sadness',\n",
              "        'neutral', 'neutral', 'worry', 'sadness'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaSgqhA8W9_"
      },
      "source": [
        "## Make numeric labels\n",
        "\n",
        "We're going to create one hot and label encoded labels.\n",
        "\n",
        "We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels \n",
        "\n",
        "To numerically encode labels we'll use Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [`LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKxsCOxFRECT"
      },
      "source": [
        "### One hot encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_V4Sobi8ZtV"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels.reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_labels.reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_labels.reshape(-1,1))"
      ],
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u52Pm0GF8W1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a999c5d9-29d5-4b19-fb4e-4cc3e1dc08bf"
      },
      "source": [
        "train_labels_one_hot, train_labels_one_hot.shape"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 1., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]), (44469, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3rFuEd8WzX"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v45G8F88Ww_"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABKK4hCu8Wuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852feee3-887c-4a03-9d12-34141960119b"
      },
      "source": [
        "val_labels_encoded, val_labels_encoded.shape"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 9,  6,  0, ...,  1, 11, 10]), (4941,))"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGl0621R8WsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdf57f3-27e1-4ca3-8a4b-f841ef9b4cdf"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, array(['anger', 'fear', 'fun', 'happiness', 'hate', 'joy', 'love',\n",
              "        'neutral', 'relief', 'sadness', 'surprise', 'worry'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW2pj-CHS2v2"
      },
      "source": [
        "## Starting a Series of Modelling Experiments\n",
        "\n",
        "We've proprocessed our data so now, in true machine learning fashion, it's time to setup a series of modelling experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUcmO6_6UQxX"
      },
      "source": [
        "## Model 0: Getting a baseline\n",
        "\n",
        "Our first model will be a TF-IDF Multinomial Naive Bayes as recommended by [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
        "\n",
        "To build it, we'll create a Scikit-Learn `Pipeline` which uses the [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) aglorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmDn3lDh8Wpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b396b294-e4e5-452f-9037-9162e406e3ca"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf_idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded)"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf_idf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtIo3-6Q8Wnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e143bd51-a74b-414c-c99a-8633285b6535"
      },
      "source": [
        "# Evaluate baseline model on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22384132766646428"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wspxGK_4X2_3",
        "outputId": "5f6322f6-45fd-4376-9a3a-fcffc38b6f84"
      },
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 9, 9, ..., 9, 9, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar9Y6tzGXkmL"
      },
      "source": [
        "### Download helper function script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBi2zDElS2UN",
        "outputId": "636444b4-ca7b-48cb-9167-0494814525bd"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-23 00:58:27--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-23 00:58:28 (80.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5LxQJW5ZiEW"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results2(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision*100,\n",
        "                  \"recall\": model_recall*100,\n",
        "                  \"f1\": model_f1*100}\n",
        "  return model_results"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU6zfkUKS2RW"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcDYNlmeS2Ot",
        "outputId": "ef0c3464-f1d3-446b-9c24-26c5aa7decbc"
      },
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results2(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 22.384132766646427,\n",
              " 'f1': 14.277496460870474,\n",
              " 'precision': 19.88909756815203,\n",
              " 'recall': 22.384132766646427}"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxDp0s50Z_-B"
      },
      "source": [
        "## Preparing the data for deep sequence models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe0DtvtSZ_y3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A3RJMeXZ_wg",
        "outputId": "b29b0404-c29c-40fe-f857-3ad9fe3d4ba3"
      },
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len "
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.948885740628302"
            ]
          },
          "metadata": {},
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Fcsfv511Z_tx",
        "outputId": "21619bfd-1eb1-4c30-877d-9e42793ef095"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=40);"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQWElEQVR4nO3df6xkZX3H8fenFGwjJEDYbnDZdtGsbbBpkWzRRmNojQj4B5oYAkntxtqsbdhEE5u4+A9Wg6GNPxpTQ7OGLZAoW1K1bCwprpTG+oe4F7sCC1JuEcJult1rqT8aExv02z/m2XZc7p37c+fO7PN+JTdz5nvOnPudA3zuw3POnElVIUnqwy+sdwOSpPEx9CWpI4a+JHXE0Jekjhj6ktSRX1zvBka54IILasuWLevdhiRNlYcffvh7VbVhvnUTHfpbtmxhZmZmvduQpKmS5NmF1jm9I0kdMfQlqSOGviR1xNCXpI4Y+pLUkUVDP8nmJA8meTzJoSTva/UPJzmS5GD7uWboNTclmU3yZJK3DtWvarXZJLtOzVuSJC1kKZdsvgh8oKq+leQc4OEk+9u6T1XVx4c3TnIJcD3wGuAVwFeTvLqt/gzwFuAwcCDJvqp6fC3eiCRpcYuGflUdBY625R8leQLYNOIl1wJ7q+onwHeTzAKXt3WzVfU0QJK9bVtDX5LGZFlz+km2AK8FHmqlnUkeSbInyXmttgl4buhlh1ttofrJv2NHkpkkM3Nzc8tpT5K0iCV/IjfJ2cAXgPdX1Q+T3AZ8FKj2+Angj1bbUFXtBnYDbNu2zW94OcmWXf84cv0zt75tTJ1ImkZLCv0kZzII/M9V1RcBqurY0PrPAl9uT48Am4deflGrMaIuSRqDpVy9E+B24Imq+uRQ/cKhzd4BPNaW9wHXJ3lZkouBrcA3gQPA1iQXJzmLwcnefWvzNiRJS7GUkf4bgHcBjyY52GofAm5IcimD6Z1ngPcCVNWhJPcwOEH7InBjVf0UIMlO4H7gDGBPVR1aw/ciSVrEUq7e+TqQeVbdN+I1twC3zFO/b9TrJEmnlp/IlaSOTPT99Hu02NU5p3LfXvkjnf4c6UtSRwx9SeqIoS9JHTH0Jakjhr4kdcSrd04zq7n6Z9RrvbJHOj040pekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR7zh2ing1xJKmlSO9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOuLVOxoLv4pRmgyO9CWpI4a+JHXE0JekjjinrzWx2KeQJU0GR/qS1BFDX5I6smjoJ9mc5MEkjyc5lOR9rX5+kv1JnmqP57V6knw6yWySR5JcNrSv7W37p5JsP3VvS5I0n6WM9F8EPlBVlwCvB25McgmwC3igqrYCD7TnAFcDW9vPDuA2GPyRAG4GXgdcDtx84g+FJGk8Fj2RW1VHgaNt+UdJngA2AdcCV7TN7gT+Bfhgq99VVQV8I8m5SS5s2+6vqhcAkuwHrgLuXsP3MxaetJQ0rZY1p59kC/Ba4CFgY/uDAPA8sLEtbwKeG3rZ4VZbqH7y79iRZCbJzNzc3HLakyQtYsmhn+Rs4AvA+6vqh8Pr2qi+1qKhqtpdVduqatuGDRvWYpeSpGZJoZ/kTAaB/7mq+mIrH2vTNrTH461+BNg89PKLWm2huiRpTBad008S4Hbgiar65NCqfcB24Nb2eO9QfWeSvQxO2v6gqo4muR/42NDJ2yuBm9bmbWia+fWS0vgs5RO5bwDeBTya5GCrfYhB2N+T5D3As8B1bd19wDXALPBj4N0AVfVCko8CB9p2HzlxUleSNB5LuXrn60AWWP3mebYv4MYF9rUH2LOcBiVJa8dP5EpSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BG/LlETb9Qndv20rrQ8jvQlqSOGviR1xNCXpI4Y+pLUEUNfkjri1Tuaat6LX1oeR/qS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE6/TVNe/gqd440pekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSNep7+Axe7TLknTyNCXFuAXtOh05PSOJHVk0dBPsifJ8SSPDdU+nORIkoPt55qhdTclmU3yZJK3DtWvarXZJLvW/q1IkhazlOmdO4C/Bu46qf6pqvr4cCHJJcD1wGuAVwBfTfLqtvozwFuAw8CBJPuq6vFV9C6tK+/bo2m0aOhX1deSbFni/q4F9lbVT4DvJpkFLm/rZqvqaYAke9u2hr4kjdFq5vR3JnmkTf+c12qbgOeGtjncagvVXyLJjiQzSWbm5uZW0Z4k6WQrDf3bgFcBlwJHgU+sVUNVtbuqtlXVtg0bNqzVbiVJrPCSzao6dmI5yWeBL7enR4DNQ5te1GqMqEunHS/31KRa0Ug/yYVDT98BnLiyZx9wfZKXJbkY2Ap8EzgAbE1ycZKzGJzs3bfytiVJK7HoSD/J3cAVwAVJDgM3A1ckuRQo4BngvQBVdSjJPQxO0L4I3FhVP2372QncD5wB7KmqQ2v+biRJIy3l6p0b5infPmL7W4Bb5qnfB9y3rO4kSWvK2zBIE8jPAOhU8TYMktQRQ1+SOuL0jjRlvBxUq+FIX5I6YuhLUkec3pFOM07/aBRH+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SO+OEsqTPetrlvjvQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOeO8dSf/HL1U//TnSl6SOGPqS1BFDX5I6YuhLUkcMfUnqyKKhn2RPkuNJHhuqnZ9kf5Kn2uN5rZ4kn04ym+SRJJcNvWZ72/6pJNtPzduRJI2ylJH+HcBVJ9V2AQ9U1VbggfYc4Gpga/vZAdwGgz8SwM3A64DLgZtP/KGQJI3PoqFfVV8DXjipfC1wZ1u+E3j7UP2uGvgGcG6SC4G3Avur6oWq+i9gPy/9QyJJOsVWOqe/saqOtuXngY1teRPw3NB2h1ttofpLJNmRZCbJzNzc3ArbkyTNZ9UncquqgFqDXk7sb3dVbauqbRs2bFir3UqSWHnoH2vTNrTH461+BNg8tN1FrbZQXZI0Riu9984+YDtwa3u8d6i+M8leBidtf1BVR5PcD3xs6OTtlcBNK29b0qTxvj3TYdHQT3I3cAVwQZLDDK7CuRW4J8l7gGeB69rm9wHXALPAj4F3A1TVC0k+Chxo232kqk4+OSxJOsUWDf2qumGBVW+eZ9sCblxgP3uAPcvqTpK0pvxEriR1pNv76S82/yhJpyNH+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHWk2/vpSxovv0N3MjjSl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHvOGapIkw6oZs3oxt7TjSl6SOrCr0kzyT5NEkB5PMtNr5SfYneao9ntfqSfLpJLNJHkly2Vq8AUnS0q3FSP/3qurSqtrWnu8CHqiqrcAD7TnA1cDW9rMDuG0NfrckaRlOxfTOtcCdbflO4O1D9btq4BvAuUkuPAW/X5K0gNWGfgFfSfJwkh2ttrGqjrbl54GNbXkT8NzQaw+32s9JsiPJTJKZubm5VbYnSRq22qt33lhVR5L8CrA/yXeGV1ZVJanl7LCqdgO7AbZt27as10qSRlvVSL+qjrTH48CXgMuBYyembdrj8bb5EWDz0MsvajVJ0pisOPSTvDzJOSeWgSuBx4B9wPa22Xbg3ra8D/jDdhXP64EfDE0DSZLGYDXTOxuBLyU5sZ/PV9U/JTkA3JPkPcCzwHVt+/uAa4BZ4MfAu1fxuyVJK7Di0K+qp4Hfnqf+n8Cb56kXcONKf58kafX8RK4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyGn9JSqjvpRBknrkSF+SOmLoS1JHDH1J6oihL0kdOa1P5Eo6PSx2UcYzt75tTJ1MP0f6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjribRgkTb1Rt2nwFg0/z5G+JHXE0Jekjhj6ktQRQ1+SOuKJXEld6+1e/Y70Jakjhr4kdcTQl6SOGPqS1BFP5ErSCKfbp33HPtJPclWSJ5PMJtk17t8vST0b60g/yRnAZ4C3AIeBA0n2VdXj4+xDktbCNF7uOe6R/uXAbFU9XVX/A+wFrh1zD5LUrVTV+H5Z8k7gqqr64/b8XcDrqmrn0DY7gB3t6a8DT86zqwuA753idk+Vae3dvsfLvsfrdOv716pqw3wvmLgTuVW1G9g9apskM1W1bUwtralp7d2+x8u+x6unvsc9vXME2Dz0/KJWkySNwbhD/wCwNcnFSc4Crgf2jbkHSerWWKd3qurFJDuB+4EzgD1VdWgFuxo5/TPhprV3+x4v+x6vbvoe64lcSdL68jYMktQRQ1+SOjJ1oT+tt3FI8kySR5McTDKz3v0sJMmeJMeTPDZUOz/J/iRPtcfz1rPHhSzQ+4eTHGnH/WCSa9azx5Ml2ZzkwSSPJzmU5H2tPtHHfETfE328AZL8UpJvJvl26/3PW/3iJA+1bPm7drHJxBjR9x1Jvjt0zC8duaOqmpofBid//wN4JXAW8G3gkvXua4m9PwNcsN59LKHPNwGXAY8N1f4S2NWWdwF/sd59LqP3DwN/tt69jej5QuCytnwO8O/AJZN+zEf0PdHHu/Ub4Oy2fCbwEPB64B7g+lb/G+BP17vXJfZ9B/DOpe5n2kb63sbhFKuqrwEvnFS+FrizLd8JvH2sTS3RAr1PtKo6WlXfass/Ap4ANjHhx3xE3xOvBv67PT2z/RTw+8Dft/okHvOF+l6WaQv9TcBzQ88PMyX/ojH4h/OVJA+3W01Mk41VdbQtPw9sXM9mVmBnkkfa9M9ETZMMS7IFeC2DEdzUHPOT+oYpON5JzkhyEDgO7Gcwg/D9qnqxbTKR2XJy31V14pjf0o75p5K8bNQ+pi30p9kbq+oy4GrgxiRvWu+GVqIG/285Tdf53ga8CrgUOAp8Yn3bmV+Ss4EvAO+vqh8Or5vkYz5P31NxvKvqp1V1KYO7AlwO/MY6t7QkJ/ed5DeBmxj0/zvA+cAHR+1j2kJ/am/jUFVH2uNx4EsM/kWbFseSXAjQHo+vcz9LVlXH2n8oPwM+ywQe9yRnMgjOz1XVF1t54o/5fH1Pw/EeVlXfBx4Efhc4N8mJD6xOdLYM9X1Vm2qrqvoJ8LcscsynLfSn8jYOSV6e5JwTy8CVwGOjXzVR9gHb2/J24N517GVZTgRn8w4m7LgnCXA78ERVfXJo1UQf84X6nvTjDZBkQ5Jz2/IvM/h+jycYhOg722aTeMzn6/s7Q4ODMDgPMfKYT90nctslYH/F/9/G4ZZ1bmlRSV7JYHQPg1tffH5S+05yN3AFg1u2HgNuBv6BwZUNvwo8C1xXVRN3wnSB3q9gMNVQDK6geu/QXPm6S/JG4F+BR4GftfKHGMyPT+wxH9H3DUzw8QZI8lsMTtSewWDge09VfaT9d7qXwRTJvwF/0EbPE2FE3/8MbGBwdc9B4E+GTvi+dD/TFvqSpJWbtukdSdIqGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI/8LYWqZ6daT1fAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-hRaB7fatoc"
      },
      "source": [
        "Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n",
        "\n",
        "We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWkPQHLuZ_rQ",
        "outputId": "724fbeec-e7d5-464f-92fe-5f87eaea4766"
      },
      "source": [
        "# How long of a sentence length covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qtnAdWWa53V"
      },
      "source": [
        "It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 25 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3R4KKMwS2L_"
      },
      "source": [
        "## Create text vectorizer layer\n",
        "\n",
        "To do so, we'll use the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer from TensorFlow.\n",
        "\n",
        "We'll keep all the parameters default except for `max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VALlioGoS2Jd",
        "outputId": "d342d127-a856-480e-801b-c462f85d80f9"
      },
      "source": [
        "# How many words are in our vocab?\n",
        "from collections import Counter\n",
        "results = Counter()\n",
        "df[\"text\"].str.lower().str.split().apply(results.update)\n",
        "len(results)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56429"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaTJPMY7cT0o"
      },
      "source": [
        "max_tokens = 56000"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWAj-3XVS2G9"
      },
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
        "                                    output_sequence_length=output_seq_len)"
      ],
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXgPUmTAbbJS"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8QTDeTFbbG1",
        "outputId": "ae6433eb-b23a-45fa-a96c-8411f6d714ed"
      },
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"Length of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "i miss coffee\n",
            "Length of text: 3\n",
            "\n",
            "Vectorized text:\n",
            "[[  2  70 433   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2sU7vifbbEH",
        "outputId": "3bc918ac-1167-420e-d478-df027c2a603b"
      },
      "source": [
        "# How many words in our training vocabulary\n",
        "text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocab: {len(text_vocab)}\")\n",
        "print(f\"Most common words in vocab: {text_vocab[:5]}\")\n",
        "print(f\"Least common words in vocab: {text_vocab[-5:]}\")"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 33117\n",
            "Most common words in vocab: ['', '[UNK]', 'i', 'to', 'the']\n",
            "Least common words in vocab: ['024', '010', '002', '0003', '00']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp4XgoG1bbBf",
        "outputId": "87b97828-db69-40ee-b619-b9c03d163cf3"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'max_tokens': 56000,\n",
              " 'name': 'text_vectorization_6',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 25,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eysbi4Pfd8gy"
      },
      "source": [
        "# Create custom text embedding\n",
        "token_embed = layers.Embedding(input_dim=len(text_vocab),\n",
        "                               output_dim=128,\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\")"
      ],
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaPljCtTd8et",
        "outputId": "82efa0ef-c4d4-4efb-f458-3feff416481b"
      },
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentece after vectorization (before the embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentece after embedding: {embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentece shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            "i miss coffee\n",
            "\n",
            "Sentece after vectorization (before the embedding):\n",
            "[[  2  70 433   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0]]\n",
            "\n",
            "Sentece after embedding: [[[ 9.2338771e-05 -1.7381370e-02 -3.1811439e-02 ...  2.3088183e-02\n",
            "   -3.9630093e-02 -1.7506849e-02]\n",
            "  [-4.6393860e-02  2.3282614e-02  2.0070497e-02 ... -4.0197253e-02\n",
            "   -4.5490742e-02 -1.4603674e-02]\n",
            "  [-2.8728986e-02 -4.3805946e-02  7.9753287e-03 ...  1.0866262e-02\n",
            "   -1.4313530e-02  3.3111405e-02]\n",
            "  ...\n",
            "  [ 3.6201645e-02 -1.0732077e-02  4.4356573e-02 ...  4.4851433e-02\n",
            "    3.4150515e-02  1.5451793e-02]\n",
            "  [ 3.6201645e-02 -1.0732077e-02  4.4356573e-02 ...  4.4851433e-02\n",
            "    3.4150515e-02  1.5451793e-02]\n",
            "  [ 3.6201645e-02 -1.0732077e-02  4.4356573e-02 ...  4.4851433e-02\n",
            "    3.4150515e-02  1.5451793e-02]]]\n",
            "\n",
            "Embedded sentece shape: (1, 25, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ab39VPMeqg-"
      },
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n",
        "\n",
        "Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
        "\n",
        "To create a batched `PrefetchDataset` we can use the methods [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) and [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), the parameter [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE) will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2AoIbzXd8cK",
        "outputId": "711c07e2-b542-48e9-c2c9-bfc705bf87c7"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (12,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7V03MEAd8Zi"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERiR2CLWg24P"
      },
      "source": [
        "## Model 1: Conv1D with token embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpmXML28d8XD"
      },
      "source": [
        "# Create 1D conv model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.MaxPooling1D(pool_size=2, padding=\"valid\")(x)\n",
        "x = layers.MaxPooling1D(pool_size=2, padding=\"valid\")(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)  #condense the output of our vector from conv layer\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3p3FaJ2qJpN"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CnafsTxd8Ua",
        "outputId": "c6ee9f04-1844-4e76-a46c-8c081af91bff"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_6 (TextVe (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 25, 128)           4238976   \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 25, 64)            41024     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_18 (MaxPooling (None, 12, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 6, 64)             0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_17  (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 4,280,780\n",
            "Trainable params: 4,280,780\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkM8UNwphrPJ",
        "outputId": "e44c325b-4b35-41e5-b8ba-6a96f5ac99a1"
      },
      "source": [
        "# Fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              validation_data=val_dataset)"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1390/1390 [==============================] - 17s 12ms/step - loss: 2.1687 - accuracy: 0.2518 - val_loss: 2.1076 - val_accuracy: 0.2763\n",
            "Epoch 2/3\n",
            "1390/1390 [==============================] - 16s 11ms/step - loss: 1.9649 - accuracy: 0.3269 - val_loss: 2.1693 - val_accuracy: 0.2657\n",
            "Epoch 3/3\n",
            "1390/1390 [==============================] - 16s 11ms/step - loss: 1.7065 - accuracy: 0.4178 - val_loss: 2.3888 - val_accuracy: 0.2338\n"
          ]
        }
      ]
    }
  ]
}