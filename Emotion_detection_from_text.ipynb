{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_detection_from_text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CubYcwcQTSoP"
      },
      "source": [
        "#EmDet\n",
        "\n",
        "Purpose of this project is to build an NLP model to predict the emotion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhUAH37gecUX"
      },
      "source": [
        "## Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaAbtJzweFqx",
        "outputId": "2cbaf450-bbb8-4ac8-bacf-4407aa64a34b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/egehanasal/Emotion-Detection-From-Text/main/data/Cleaned%20Data/emotion_data_cleaned.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-26 23:08:06--  https://raw.githubusercontent.com/egehanasal/Emotion-Detection-From-Text/main/data/Cleaned%20Data/emotion_data_cleaned.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4226326 (4.0M) [text/plain]\n",
            "Saving to: ‘emotion_data_cleaned.csv’\n",
            "\n",
            "emotion_data_cleane 100%[===================>]   4.03M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-10-26 23:08:07 (103 MB/s) - ‘emotion_data_cleaned.csv’ saved [4226326/4226326]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-G6VOlOeLvO",
        "outputId": "cb953853-d22d-406c-e420-2a3cde43a839"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"emotion_data_cleaned.csv\")\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56427 entries, 0 to 56426\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    56334 non-null  object\n",
            " 1   target  56427 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 881.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpMyw41xfMh2"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6QBklG8fB2j",
        "outputId": "bf867596-573c-4593-8416-2e722c6c82ad"
      },
      "source": [
        "import numpy as np\n",
        "np.where(pd.isnull(df))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  608,  2911,  4446,  4508,  4993,  5876,  6296,  6502,  6806,\n",
              "         7472,  7918,  8032,  8328,  8984,  9841, 10044, 10076, 10203,\n",
              "        11079, 12608, 12712, 13738, 13915, 14366, 14461, 15033, 15129,\n",
              "        16201, 16320, 18421, 18569, 18834, 20199, 20375, 20926, 22303,\n",
              "        22609, 22684, 22710, 23745, 24038, 24666, 25440, 25590, 25785,\n",
              "        25921, 26680, 26785, 27405, 27819, 28280, 28303, 29139, 29731,\n",
              "        29759, 30660, 33759, 33942, 34424, 34693, 35109, 38075, 40378,\n",
              "        41913, 41975, 42460, 43343, 43763, 43969, 44273, 44939, 45385,\n",
              "        45499, 45795, 46451, 47308, 47511, 47543, 47670, 48546, 50075,\n",
              "        50179, 51205, 51382, 51833, 51928, 52500, 52596, 53668, 53787,\n",
              "        55888, 56036, 56301]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZowwyDqtfKBh",
        "outputId": "87353225-4881-4547-c0c5-4f09dfc18e1c"
      },
      "source": [
        "np.where(df.applymap(lambda x: x == ''))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-XIVH06ehTB"
      },
      "source": [
        "Drop the null lines and check the data again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAzLv2qEfZ9K"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMg9YT5vfaQB",
        "outputId": "818c78e5-4e35-4c61-b129-35f60306c7b0"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56334 entries, 0 to 56426\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    56334 non-null  object\n",
            " 1   target  56334 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "NPg9pVtgfaNN",
        "outputId": "acb52fda-8e0d-467e-dd44-023c7f884b8e"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We want to trade with someone who has Houston ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Re-pinging why didn't you go to prom? BC my bf...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I should be sleep, but im not! thinking about ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hmmm. is down</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Charlene my love. I miss you</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I'm sorry at least it's Friday?</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cant fall asleep</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Choked on her retainers</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   target\n",
              "0                Funeral ceremony...gloomy friday...  sadness\n",
              "1               wants to hang out with friends SOON!  sadness\n",
              "2  We want to trade with someone who has Houston ...      joy\n",
              "3  Re-pinging why didn't you go to prom? BC my bf...  neutral\n",
              "4  I should be sleep, but im not! thinking about ...     fear\n",
              "5                                      Hmmm. is down  sadness\n",
              "6                       Charlene my love. I miss you     fear\n",
              "7                    I'm sorry at least it's Friday?  sadness\n",
              "8                                   cant fall asleep  sadness\n",
              "9                            Choked on her retainers  neutral"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGyFwxPWfaKF",
        "outputId": "4d1f6113-e098-4043-f7fa-96b56e0e9c74"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "df.target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "joy        16999\n",
              "fear       10700\n",
              "sadness    10638\n",
              "neutral     8626\n",
              "love        5386\n",
              "anger       3985\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flQRsngz-Can"
      },
      "source": [
        "Before splitting our data, let's shuffle it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "f9Y936RI-Gkm",
        "outputId": "3bcccede-77be-481a-f54d-809478fb775c"
      },
      "source": [
        "# Shuffle the dataframe\n",
        "df_shuffled = df.sample(frac=1)\n",
        "df_shuffled.head(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16724</th>\n",
              "      <td>damn...plans were canceled.....another friday ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31855</th>\n",
              "      <td>Aiden KNIVES out May 12th www.myspace.com/aide...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51586</th>\n",
              "      <td>I was supposed to go boating/songwriting in Ca...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31917</th>\n",
              "      <td>nice one</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23896</th>\n",
              "      <td>How I Met Your Mother? Best show ever</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11480</th>\n",
              "      <td>No one is bringing snacks</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31484</th>\n",
              "      <td>off to pearlyn's place - gran's bday + mothers...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49815</th>\n",
              "      <td>i can't i can't i can't i'm sad.... i'm from v...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15588</th>\n",
              "      <td>it's best if i check it while it IS up. when i...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20879</th>\n",
              "      <td>hope this day will be nice as the sun that are...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text   target\n",
              "16724  damn...plans were canceled.....another friday ...     fear\n",
              "31855  Aiden KNIVES out May 12th www.myspace.com/aide...  sadness\n",
              "51586  I was supposed to go boating/songwriting in Ca...  sadness\n",
              "31917                                           nice one     love\n",
              "23896              How I Met Your Mother? Best show ever  neutral\n",
              "11480                          No one is bringing snacks  neutral\n",
              "31484  off to pearlyn's place - gran's bday + mothers...  neutral\n",
              "49815  i can't i can't i can't i'm sad.... i'm from v...      joy\n",
              "15588  it's best if i check it while it IS up. when i...  sadness\n",
              "20879  hope this day will be nice as the sun that are...      joy"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSuRso1a8rSQ"
      },
      "source": [
        "### Split the data to train, val and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pioMjj0_8wAr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                          df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                          test_size=0.15)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwadh183Bpk2"
      },
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences,\n",
        "                                                                        train_labels,\n",
        "                                                                        test_size=0.1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swe0vsSr-b0U",
        "outputId": "b01d30f3-63f4-4bac-e73d-c7e1916b7252"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels), len(test_sentences), len(test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43094, 43094, 4789, 4789, 8451, 8451)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y534R70T8wDz",
        "outputId": "3534ea01-d3fb-4b15-bc34-a8ae84362840"
      },
      "source": [
        "# View first 10 lines of training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['is still missing her husband. I really want him home.',\n",
              "        \"Ugh my neck really hurts I'm out aquatards, xox\",\n",
              "        \"Good morning to you, however it's night time for me, so I am off to bed *hugs* Have a great day\",\n",
              "        'hopes whoever stole my purse and money gets what is coming to them',\n",
              "        'GOSSIP GIRL, WHEN ARE YOU COMING BACK ! chaceeeeeee..',\n",
              "        'MY CAR IS ALMOST DEFINATELY GOING TO BE WRITTEN OFF! THE GARAGE RANG AND SAID THE WORK WILL COST 3K AND ITS UP TO THE INSURANCE CO',\n",
              "        'will have to pare down his collection of portraits of and bangbang',\n",
              "        \"I ate to much lunch...now I don't want to work\",\n",
              "        \": i know i*m late but i didn't had internet. so happy bithday to you and pierre!\",\n",
              "        'Today just fucking sucks for me!!'], dtype=object),\n",
              " array(['neutral', 'joy', 'love', 'fear', 'anger', 'joy', 'sadness',\n",
              "        'neutral', 'fear', 'fear'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jaSgqhA8W9_"
      },
      "source": [
        "## Make numeric labels\n",
        "\n",
        "We're going to create one hot and label encoded labels.\n",
        "\n",
        "We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels \n",
        "\n",
        "To numerically encode labels we'll use Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [`LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKxsCOxFRECT"
      },
      "source": [
        "### One hot encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_V4Sobi8ZtV"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels.reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_labels.reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_labels.reshape(-1,1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u52Pm0GF8W1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9701228-dbb9-4e3f-8b8b-522b8bf6b65f"
      },
      "source": [
        "train_labels_one_hot, train_labels_one_hot.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.]]), (43094, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3rFuEd8WzX"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v45G8F88Ww_"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABKK4hCu8Wuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0004bd3a-354b-4b57-ea76-eb88be00ce5d"
      },
      "source": [
        "val_labels_encoded, val_labels_encoded.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2, 2, 1, ..., 1, 1, 4]), (4789,))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGl0621R8WsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b616d4de-dea5-480a-98ff-e2523d060c22"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6,\n",
              " array(['anger', 'fear', 'joy', 'love', 'neutral', 'sadness'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW2pj-CHS2v2"
      },
      "source": [
        "## Starting a Series of Modelling Experiments\n",
        "\n",
        "We've proprocessed our data so now, in true machine learning fashion, it's time to setup a series of modelling experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUcmO6_6UQxX"
      },
      "source": [
        "## Model 0: Getting a baseline\n",
        "\n",
        "Our first model will be a TF-IDF Multinomial Naive Bayes as recommended by [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
        "\n",
        "To build it, we'll create a Scikit-Learn `Pipeline` which uses the [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) aglorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmDn3lDh8Wpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674a1a05-4242-4d52-8e11-7cb44b972dc0"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf_idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf_idf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtIo3-6Q8Wnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ce55ec-9a66-4c8f-f00e-75368a1eb17f"
      },
      "source": [
        "# Evaluate baseline model on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29525997076633953"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wspxGK_4X2_3",
        "outputId": "63bfeec8-817e-4a9a-e828-ce769062827c"
      },
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 4, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar9Y6tzGXkmL"
      },
      "source": [
        "### Download helper function script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBi2zDElS2UN",
        "outputId": "578cc026-d4f3-4486-e449-270e3d127718"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-26 23:11:24--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-26 23:11:24 (69.0 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5LxQJW5ZiEW"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results2(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision*100,\n",
        "                  \"recall\": model_recall*100,\n",
        "                  \"f1\": model_f1*100}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU6zfkUKS2RW"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcDYNlmeS2Ot",
        "outputId": "694f8bbd-6832-4637-d367-7f37ec9ce05f"
      },
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 29.525997076633953,\n",
              " 'f1': 0.16023839091061232,\n",
              " 'precision': 0.20465832344122095,\n",
              " 'recall': 0.29525997076633953}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxDp0s50Z_-B"
      },
      "source": [
        "## Preparing the data for deep sequence models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe0DtvtSZ_y3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A3RJMeXZ_wg",
        "outputId": "c6db999b-51cb-4373-9e13-962f4536d81c"
      },
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.143894741727387"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Fcsfv511Z_tx",
        "outputId": "5282659d-bf3f-49c6-9e3e-7c417cabf66f"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=20);"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-hRaB7fatoc"
      },
      "source": [
        "Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n",
        "\n",
        "We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWkPQHLuZ_rQ",
        "outputId": "a61b0b1c-a77e-44ee-9178-9b28fdfb9b69"
      },
      "source": [
        "# How long of a sentence length covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qtnAdWWa53V"
      },
      "source": [
        "It looks like 95% of the sentences in our training set have a length of 26 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 26 get padded with zeros and sentences with a length above 26 get truncated (words after 26 get cut off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3R4KKMwS2L_"
      },
      "source": [
        "## Create text vectorizer layer\n",
        "\n",
        "To do so, we'll use the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer from TensorFlow.\n",
        "\n",
        "We'll keep all the parameters default except for `max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VALlioGoS2Jd",
        "outputId": "e0806d7c-ddb7-46cc-cbc9-251b0e5ae831"
      },
      "source": [
        "# How many words are in our vocab?\n",
        "from collections import Counter\n",
        "results = Counter()\n",
        "df[\"text\"].str.lower().str.split().apply(results.update)\n",
        "len(results)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52478"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaTJPMY7cT0o"
      },
      "source": [
        "max_tokens = 52450"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWAj-3XVS2G9"
      },
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
        "                                    output_sequence_length=output_seq_len)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXgPUmTAbbJS"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8QTDeTFbbG1",
        "outputId": "21b96c75-e0a6-4950-8e96-c33fa060c262"
      },
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"Length of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "she could have been a lost dog poor girl\n",
            "Length of text: 9\n",
            "\n",
            "Vectorized text:\n",
            "[[129 126  18  93   5 238 442 258 235   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2sU7vifbbEH",
        "outputId": "4ca13705-41c8-4c4c-9a31-74cc3916aa21"
      },
      "source": [
        "# How many words in our training vocabulary\n",
        "text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocab: {len(text_vocab)}\")\n",
        "print(f\"Most common words in vocab: {text_vocab[:5]}\")\n",
        "print(f\"Least common words in vocab: {text_vocab[-5:]}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 30979\n",
            "Most common words in vocab: ['', '[UNK]', 'i', 'to', 'the']\n",
            "Least common words in vocab: ['050809', '0405', '0128', '002', '0003']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp4XgoG1bbBf",
        "outputId": "51db80f0-675f-4842-fa04-4436bedee53d"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'max_tokens': 52450,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 26,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eysbi4Pfd8gy"
      },
      "source": [
        "# Create custom text embedding\n",
        "token_embed = layers.Embedding(input_dim=len(text_vocab),\n",
        "                               output_dim=128,\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaPljCtTd8et",
        "outputId": "0772668d-7898-4a10-b368-c8d60fc2014b"
      },
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentece after vectorization (before the embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentece after embedding: {embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentece shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            "she could have been a lost dog poor girl\n",
            "\n",
            "Sentece after vectorization (before the embedding):\n",
            "[[129 126  18  93   5 238 442 258 235   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0]]\n",
            "\n",
            "Sentece after embedding: [[[ 0.03173027 -0.01559976  0.03681542 ... -0.02692878 -0.03425299\n",
            "   -0.03108492]\n",
            "  [ 0.04283258  0.007278    0.02346243 ... -0.01573937  0.04494167\n",
            "   -0.00732989]\n",
            "  [ 0.03748336 -0.0249019  -0.04101027 ...  0.01040881 -0.02549201\n",
            "    0.01156831]\n",
            "  ...\n",
            "  [ 0.03378799  0.01039431 -0.04368934 ...  0.03934186 -0.01143274\n",
            "    0.00161328]\n",
            "  [ 0.03378799  0.01039431 -0.04368934 ...  0.03934186 -0.01143274\n",
            "    0.00161328]\n",
            "  [ 0.03378799  0.01039431 -0.04368934 ...  0.03934186 -0.01143274\n",
            "    0.00161328]]]\n",
            "\n",
            "Embedded sentece shape: (1, 26, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ab39VPMeqg-"
      },
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n",
        "\n",
        "Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
        "\n",
        "To create a batched `PrefetchDataset` we can use the methods [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) and [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), the parameter [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE) will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2AoIbzXd8cK",
        "outputId": "0d14754a-44ca-4805-e460-9c6d9a2c3e9c"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (6,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7V03MEAd8Zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748b43aa-50b8-4ead-b3cf-68df189a230a"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 6)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERiR2CLWg24P"
      },
      "source": [
        "## Model 1: Conv1D with token embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpmXML28d8XD"
      },
      "source": [
        "# Create 1D conv model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(16, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.MaxPooling1D(pool_size=2, padding=\"valid\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.MaxPooling1D(pool_size=2, padding=\"valid\")(x)\n",
        "x = layers.Dropout(0.6)(x)\n",
        "x = layers.MaxPooling1D(pool_size=3, padding=\"valid\")(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)  #condense the output of our vector from conv layer\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3p3FaJ2qJpN"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"Adam\",\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CnafsTxd8Ua",
        "outputId": "ec36c3e8-03ec-4093-d18e-a641e1bb55c9"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 26)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 26, 128)           3965312   \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 26, 16)            10256     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling (None, 13, 16)            0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 13, 16)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 6, 16)             0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 6, 16)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 2, 16)             0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 6)                 102       \n",
            "=================================================================\n",
            "Total params: 3,975,670\n",
            "Trainable params: 3,975,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkM8UNwphrPJ",
        "outputId": "171ca7af-7642-43f0-e05d-74bce0993104"
      },
      "source": [
        "# Fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              validation_data=val_dataset)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1347/1347 [==============================] - 14s 10ms/step - loss: 1.6992 - accuracy: 0.2978 - val_loss: 1.7104 - val_accuracy: 0.2982\n",
            "Epoch 2/3\n",
            "1347/1347 [==============================] - 13s 10ms/step - loss: 1.6688 - accuracy: 0.3070 - val_loss: 1.6966 - val_accuracy: 0.2955\n",
            "Epoch 3/3\n",
            "1347/1347 [==============================] - 13s 10ms/step - loss: 1.6264 - accuracy: 0.3278 - val_loss: 1.6961 - val_accuracy: 0.2930\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRg-nJPJAzEs",
        "outputId": "5faa20e0-8a1e-4b85-c583-9ec0fa3ef074"
      },
      "source": [
        "model_1.evaluate(test_dataset)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "265/265 [==============================] - 1s 4ms/step - loss: 1.6895 - accuracy: 0.2933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6895335912704468, 0.2933380603790283]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}